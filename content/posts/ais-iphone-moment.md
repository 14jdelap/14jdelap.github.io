---
title: "Voice's impending iPhone moment"
date: "2024-02-03"
description: "Better LLM models and more efficient microprocessor architectures will lead to a new dominant interface: voice."
summary: "Better LLM models and more efficient microprocessor architectures will lead to a new dominant interface: voice."
tags: ["ai", "llm", "ui/ux", "interface design"]
categories: ["technology", "society"]
series: ["AI"]
ShowToc: true
TocOpen: true
---

Ben Thompson recently wrote in Stratechery about "The Impending VR Moment" ([link](https://stratechery.com/2024/sora-groq-and-virtual-reality/)).

I'd summarize his argument as:

- Recent AI models (like Sora) show major improvements in generating complex and photorealistic video content that may be useful for virtual reality experiences, though it still has limitations in how it represents the physical world
- Transformer-based models like Sora will run much more quickly in chips with  architectures designed for their computational needs rather than GPUs, like Groq has shown ([link](https://groq.com/))
- Thus, given the development of these technologies and AI hardware like the Apple Vision Pro or Meta Quest we're directed towards an "iPhone moment" for VR

I think Ben's right, but I also think it misses the more significant moment: these same drivers will enable voice as the next dominant interface.

## How we got to the smartphone's domination

{{< youtube GK55ElsVzxM >}}

> "So three things: a widescreen iPod with touch controls, a revolutionary mobile phone and a breakthrough internet communications device. An iPod, a phone, and an internet communicator... Are you getting it?"

The iPhone —and all succeeding smartphones— collapsed all devices into 1. It replaced paper maps (does anyone use them anymore?), personal music players like the iPod or Walkman, long-distance phone calls through WhatsApp, cameras

- The iPhone collapsed all devices into 1: maps, computers, GPS, walkmans, etc
- Thus, the reigning interface was graphical and textual (including for computers)

## Voice as an interface

## AI-powered voice agents will undermine the smartphone supremacy

## How will this change the inernet economy?

## Open questions

## Ideas


# Voice as the new interface
- Fast AI models enable a new (but also old interface: voice)
  - Voice is our oldest interface: about 200,000 years old
  - Voice has a wide throughput, expresses emotions, more personal (escuchar lo de Javier)
  - Biggest blockers: unintelligent assistants, now slow LLM models. This changes with chips and models, like Groq

# Voice will lead to an explosion of AI powered devices
- Voice as an interface means different type of devices
  - Rabbit R1: https://www.rabbit.tech/keynote
  - Humane (could be better with a voice agent, but due to timing they were caught between a rock and a hard place. I expect their 2nd iteration to be different)
- E.g. we could have Uber bookings from watches, etc -> niche of people who want less invasive digital devices
- Given that LLM models are rapidly becoming commoditised, this will create a long-tail of AI-powered products (e.g. mining tools, etc)

# Does this put Apple in an innovator's dilemma?
Devices with AI assistants make it more likely for their ancillary products to eat into iPhone sales. Thus, I think that might put Apple in an innovator's dilemma where making the best ancillary products undermine their core business. In 2023 52% of revenues came from iPhones (383.2 bn) and 39.84bn from all accessories and wearables together.

# Open questions
- What does a good UX look like with AI agents? Do people want an AI to book everything for them like a tour agency vs keeping more control over each step?
- How will the internet economy change when AI agents are the ones offering purchasing decisions? How will this change internet marketing?
- Will companies offer APIs meant for AIs? E.g. the OS agent interacting with the Spotify agent or with Spotify the app?
  - What's the role of individual companies?
