---
title: "Voice's impending iPhone moment"
date: "2024-02-03"
description: "Better LLM models and more efficient microprocessor architectures will lead to a new dominant interface: voice."
summary: "Better LLM models and more efficient microprocessor architectures will lead to a new dominant interface: voice."
tags: ["ai", "llm", "ui/ux", "interface design"]
categories: ["technology", "society"]
series: ["AI"]
ShowToc: false
TocOpen: false
---

Ben Thompson recently wrote in Stratechery about "The Impending VR Moment" ([link](https://stratechery.com/2024/sora-groq-and-virtual-reality/)).

I'd summarize his argument as:

- Recent AI models (like Sora) show major improvements in generating complex and photorealistic video content that may be useful for virtual reality experiences, though it still has limitations in how it represents the physical world
- Transformer-based models like Sora will run much more quickly in chips with  architectures designed for their computational needs rather than GPUs, like Groq has shown ([link](https://groq.com/))
- Thus, given the development of these technologies and AI hardware like the Apple Vision Pro or Meta Quest we're directed towards an "iPhone moment" for VR

I think Ben's right, but I also think it misses an equally significant moment: these same drivers will make voice the next dominant interface.

{{< youtube GK55ElsVzxM >}}
  
> "So three things: a widescreen iPod with touch controls, a revolutionary mobile phone and a breakthrough internet communications device. An iPod, a phone, and an internet communicator... Are you getting it?"

The iPhone — and all succeeding smartphones — collapsed all devices into 1. It replaced paper maps (does anyone use them anymore?), personal music players like the iPod or Walkman, long-distance phone calls through WhatsApp, cameras, newspapers and magazines, the TV and radio... and so much more.

We went from many devices to one: a monochromatic rectangle with a touchscreen.

In contrast, language is our original interface — hundreds of thousands if not millions of years old. No wonder why older people struggle with new technology (which usually involve screens) but can still solve problems by talking.

My former teacher, the inspiring Javier Cañada, recently spoke about why he thinks voice is the best interface. Some of his arguments include:

- Voice is inmaterial and doesn't take space, unlike pixels on a screen
- Voice frees up the senses as you don't need to use multiple senses simultaneously (unlike sight and gesture with graphical interfaces)
- Voice is the most accessible interface, you just need to be able to speak
- Voice has emotiveness because it has intonation
- Voice has personality, how each of us speaks is unique

While the uptick of voice assistants, like Alexa and Siri, have made voice a more prominent interface to interact with electronic products they're still notoriously insufficient to be anywhere near a complete replacement.


## AI-powered voice agents will undermine the smartphone supremacy

## How will this change the inernet economy?

## Open questions

## Ideas


# Voice as the new interface
- Fast AI models enable a new (but also old interface: voice)
  - Voice is our oldest interface: about 200,000 years old
  - Voice has a wide throughput, expresses emotions, more personal (escuchar lo de Javier)
  - Biggest blockers: unintelligent assistants, now slow LLM models. This changes with chips and models, like Groq

# Voice will lead to an explosion of AI powered devices
- Voice as an interface means different type of devices
  - Rabbit R1: https://www.rabbit.tech/keynote
  - Humane (could be better with a voice agent, but due to timing they were caught between a rock and a hard place. I expect their 2nd iteration to be different)
- E.g. we could have Uber bookings from watches, etc -> niche of people who want less invasive digital devices
- Given that LLM models are rapidly becoming commoditised, this will create a long-tail of AI-powered products (e.g. mining tools, etc)

# Does this put Apple in an innovator's dilemma?
Devices with AI assistants make it more likely for their ancillary products to eat into iPhone sales. Thus, I think that might put Apple in an innovator's dilemma where making the best ancillary products undermine their core business. In 2023 52% of revenues came from iPhones (383.2 bn) and 39.84bn from all accessories and wearables together.

# Open questions
- What does a good UX look like with AI agents? Do people want an AI to book everything for them like a tour agency vs keeping more control over each step?
- How will the internet economy change when AI agents are the ones offering purchasing decisions? How will this change internet marketing?
- Will companies offer APIs meant for AIs? E.g. the OS agent interacting with the Spotify agent or with Spotify the app?
  - What's the role of individual companies?
